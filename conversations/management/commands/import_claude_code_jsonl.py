#!/usr/bin/env python3
"""
Django management command to import single Claude Code JSONL file.

Usage:
    python manage.py import_claude_code_jsonl --file 097637c9-33b2-4806-bdcf-01540304de61.jsonl --era-id <uuid>
"""

import json
import uuid as uuid_lib
import re
from pathlib import Path
from datetime import datetime
from django.core.management.base import BaseCommand
from django.utils.dateparse import parse_datetime
from conversations.models import (
    Era, ContextHeap, ContextHeapType,
    Message, Thought, ToolUse, ToolResult, ThinkingEntity,
    CompactingAction
)
from conversations.utils.retry_detection import RetryDetector


def parse_command_xml(text):
    """Parse XML command patterns into structured data."""
    # Check for meta caveat
    if 'Caveat:' in text and 'generated by the user while running local commands' in text:
        return {
            'type': 'meta_caveat',
            'is_meta': True,
            'text': text
        }

    # Check for command invocation
    command_name_match = re.search(r'<command-name>(.+?)</command-name>', text)
    if command_name_match:
        command_message_match = re.search(r'<command-message>(.+?)</command-message>', text)
        command_args_match = re.search(r'<command-args>(.*?)</command-args>', text, re.DOTALL)

        return {
            'type': 'slash_command',
            'command_name': command_name_match.group(1),
            'command_message': command_message_match.group(1) if command_message_match else '',
            'command_args': command_args_match.group(1).strip() if command_args_match else '',
            'raw_xml': text
        }

    # Check for command output
    stdout_match = re.search(r'<local-command-stdout>(.*?)</local-command-stdout>', text, re.DOTALL)
    if stdout_match:
        return {
            'type': 'command_output',
            'stdout': stdout_match.group(1),
            'raw_xml': text
        }

    # Not a recognized pattern, return as plain text
    return text


class Command(BaseCommand):
    help = 'Import single Claude Code JSONL conversation file'

    def import_messages_into_heap(
        self,
        messages_data,
        era,
        heap_type,
        justin,
        magent,
        filename,
        starting_message_number=0
    ):
        """
        Import a slice of messages into a new ContextHeap.

        Args:
            messages_data: List of message dicts from JSONL
            era: Era to attach heap to
            heap_type: ContextHeapType (FRESH or POST_COMPACTING)
            justin, magent: ThinkingEntity objects
            filename: Source filename for messages
            starting_message_number: What message_number to start from (default 0)

        Returns:
            tuple: (context_heap, message_count, retry_count)
        """
        if not messages_data:
            return None, 0, 0

        first_msg_data = messages_data[0]

        # Determine first message details
        if first_msg_data.get('type') == 'user':
            first_sender = justin
            first_recipient = magent
            content_items = first_msg_data.get('message', {}).get('content', [])
            if isinstance(content_items, str):
                raw_text = content_items
            else:
                raw_text = ' '.join(
                    item.get('text', '') for item in content_items
                    if isinstance(item, dict) and item.get('type') == 'text'
                )
            first_content = parse_command_xml(raw_text)
        else:
            first_sender = magent
            first_recipient = justin
            content_items = first_msg_data.get('message', {}).get('content', [])
            first_content = ''
            if isinstance(content_items, str):
                first_content = content_items
            else:
                for item in content_items:
                    if isinstance(item, dict) and item.get('type') == 'text':
                        first_content = item.get('text', '')
                        break
            if not first_content:
                first_content = '[Assistant message]'

        # Create or get first message
        first_uuid = uuid_lib.UUID(first_msg_data.get('uuid'))

        # Don't skip based on existing messages - let message-level get_or_create handle deduplication
        # This allows importing files with overlapping messages while still creating proper heap structure

        timestamp_str = first_msg_data.get('timestamp')
        timestamp = None
        if timestamp_str:
            dt = parse_datetime(timestamp_str)
            if dt:
                timestamp = int(dt.timestamp() * 1000)

        first_msg, msg_created = Message.objects.get_or_create(
            id=first_uuid,
            defaults={
                'message_number': starting_message_number,
                'content': first_content,
                'context_heap': None,  # Set after creating window
                'parent': None,
                'sender': first_sender,
                'timestamp': timestamp,
                'session_id': uuid_lib.UUID(first_msg_data.get('sessionId')) if first_msg_data.get('sessionId') else None,
                'source_file': filename,
                'cwd': first_msg_data.get('cwd'),
                'git_branch': first_msg_data.get('gitBranch'),
                'client_version': first_msg_data.get('version'),
                'is_sidechain': first_msg_data.get('isSidechain', False),
                'is_continuation_message': (heap_type == ContextHeapType.POST_COMPACTING)
            }
        )
        if msg_created:
            first_msg.recipients.add(first_recipient)

        # Create context window
        context_heap = ContextHeap.objects.create(
            era=era,
            first_message=first_msg,
            type=heap_type
        )

        # Update first message to point to new heap (even if it existed in another heap)
        if first_msg.context_heap != context_heap:
            old_heap = first_msg.context_heap
            first_msg.context_heap = context_heap
            first_msg.save()
            if old_heap:
                self.stdout.write(self.style.WARNING(
                    f'Moved message {str(first_msg.id)[:8]} from heap {str(old_heap.id)[:8]} to new heap {str(context_heap.id)[:8]}'
                ))

        self.stdout.write(self.style.SUCCESS(f'Created context window {context_heap.id}'))

        # Process remaining messages using Message.from_json()
        parent = first_msg
        message_num = starting_message_number + 1

        for msg_data in messages_data[1:]:
            # Determine sender based on message type
            msg_type = msg_data.get('type')
            sender = justin if msg_type == 'user' else magent

            # Use Message.from_jsonl_claude_code_v2() to handle all polymorphic types
            results = Message.from_jsonl_claude_code_v2(
                msg_data,
                context_heap=context_heap,
                parent=parent,
                sender=sender,
                source_file=filename
            )

            # Update parent and message_number for each created message
            for message, created in results:
                if created:
                    message.message_number = message_num
                    message.save()

                    # Add recipients
                    recipient = magent if sender == justin else justin
                    message.recipients.add(recipient)

                parent = message
                message_num += 1

        # Detect retries
        all_messages = Message.objects.filter(
            context_heap=context_heap
        ).select_related('sender').order_by('message_number')

        detector = RetryDetector()
        retry_count = 0

        for msg in all_messages:
            is_retry = detector.is_retry(
                sender=msg.sender.name,
                content=str(msg.content),
                is_synthetic_error=msg.is_synthetic_error
            )

            if is_retry:
                msg.is_retry = True
                msg.save()
                retry_count += 1

        return context_heap, message_num - starting_message_number, retry_count

    def add_arguments(self, parser):
        parser.add_argument(
            '--file',
            type=str,
            required=True,
            help='JSONL file to import',
        )
        parser.add_argument(
            '--era-id',
            type=str,
            required=True,
            help='UUID of the Era to import into',
        )
        parser.add_argument(
            '--dry-run',
            action='store_true',
            help='Preview without importing',
        )

    def handle(self, *args, **options):
        filepath = Path(options['file'])
        era_id = options['era_id']
        dry_run = options['dry_run']

        if not filepath.exists():
            self.stdout.write(self.style.ERROR(f'File not found: {filepath}'))
            return

        # Get era
        try:
            era = Era.objects.get(id=era_id)
        except Era.DoesNotExist:
            self.stdout.write(self.style.ERROR(f'Era not found: {era_id}'))
            return

        # Get entities
        justin = ThinkingEntity.objects.get(name='justin')
        magent = ThinkingEntity.objects.get(name='magent')

        # Parse JSONL
        self.stdout.write(f'Parsing {filepath.name}...')
        lines = []
        summary_data = None
        with open(filepath) as f:
            for line in f:
                if not line.strip():
                    continue
                try:
                    data = json.loads(line)
                    if data.get('type') == 'summary':
                        summary_data = data
                    else:
                        lines.append(data)
                except json.JSONDecodeError:
                    pass

        self.stdout.write(f'Found {len(lines)} messages')
        if summary_data:
            self.stdout.write(f'Found summary: {summary_data.get("summary", "")[:60]}...')

        if dry_run:
            self.stdout.write('\nFirst 5 messages:')
            for i, msg_data in enumerate(lines[:5]):
                msg_type = msg_data.get('type')
                timestamp = msg_data.get('timestamp', 'no-timestamp')
                content = msg_data.get('message', {}).get('content', [])

                preview = ''
                if msg_type == 'user' and content:
                    preview = content[0].get('text', '')[:60]
                elif msg_type == 'assistant' and content:
                    for item in content:
                        if item.get('type') == 'text':
                            preview = item.get('text', '')[:60]
                            break

                self.stdout.write(f'  {i}. [{msg_type}] {timestamp} - {preview}...')
            return

        # Handle files with summary but no messages (already compacted session)
        if len(lines) == 0:
            if summary_data:
                leaf_uuid_str = summary_data.get('leafUuid')
                if leaf_uuid_str:
                    leaf_uuid = uuid_lib.UUID(leaf_uuid_str)

                    # Check if leaf message already exists in database (from earlier import)
                    context_heap = None
                    ending_message_id = None
                    preceding_message = None
                    try:
                        leaf_msg = Message.objects.get(id=leaf_uuid)
                        existing_heap = leaf_msg.context_heap
                        ending_message_id = leaf_uuid
                        preceding_message = leaf_msg

                        self.stdout.write(self.style.SUCCESS(
                            f'Found existing leaf message {str(leaf_uuid)[:8]} in heap {str(existing_heap.id)[:8]}'
                        ))

                        # Check if there are messages AFTER the leaf in the existing heap
                        # If so, we need to split the heap
                        messages_after_leaf = Message.objects.filter(
                            context_heap=existing_heap,
                            message_number__gt=leaf_msg.message_number
                        ).order_by('message_number')

                        if messages_after_leaf.exists():
                            self.stdout.write(self.style.WARNING(
                                f'Found {messages_after_leaf.count()} messages after leaf in heap {str(existing_heap.id)[:8]} - splitting heap'
                            ))

                            # Create new POST_COMPACTING heap starting with first message after leaf
                            first_continuation_msg = messages_after_leaf.first()
                            new_heap = ContextHeap.objects.create(
                                era=era,
                                first_message=first_continuation_msg,
                                type=ContextHeapType.POST_COMPACTING
                            )

                            # Move all messages after leaf to the new heap
                            for msg in messages_after_leaf:
                                msg.context_heap = new_heap
                                msg.is_continuation_message = True
                                msg.save()

                            # Renumber messages in new heap starting from 0
                            for i, msg in enumerate(Message.objects.filter(context_heap=new_heap).order_by('timestamp')):
                                msg.message_number = i
                                msg.save()

                            self.stdout.write(self.style.SUCCESS(
                                f'Created new heap {str(new_heap.id)[:8]} with {messages_after_leaf.count()} continuation messages'
                            ))

                            context_heap = new_heap
                        else:
                            # No messages after leaf - leaf is at end of heap
                            # Don't create a new heap, CompactingAction will be orphaned
                            self.stdout.write(self.style.WARNING(
                                f'Leaf is at end of heap {str(existing_heap.id)[:8]} - no continuation heap needed'
                            ))
                    except Message.DoesNotExist:
                        self.stdout.write(self.style.WARNING(
                            f'Leaf message {str(leaf_uuid)[:8]} not found - creating orphaned CA'
                        ))

                    # Use CompactingAction.from_jsonl_claude_code_v2() for creation
                    compact, created = CompactingAction.from_jsonl_claude_code_v2(
                        summary_data,
                        context_heap=context_heap,
                        ending_message_id=ending_message_id,
                        preceding_message=preceding_message
                    )

                    if not created:
                        self.stdout.write(self.style.WARNING(
                            f'CompactingAction {str(compact.id)[:8]} already exists - skipping'
                        ))
                        return

                    if context_heap:
                        self.stdout.write(self.style.SUCCESS(
                            f'Linked CompactingAction to heap {str(context_heap.id)[:8]}'
                        ))
                    else:
                        self.stdout.write(self.style.WARNING(
                            f'Created orphaned CompactingAction: {compact.summary[:60]}...'
                        ))
            return

        filename = filepath.name

        # Let message-level deduplication happen naturally via get_or_create
        # No need to skip entire files - import what we can

        # Decide whether to split at compact boundary
        if summary_data:
            leaf_uuid_str = summary_data.get('leafUuid')
            if leaf_uuid_str:
                leaf_uuid = uuid_lib.UUID(leaf_uuid_str)

                # Find leaf position in messages
                leaf_index = None
                for i, msg_data in enumerate(lines):
                    if uuid_lib.UUID(msg_data.get('uuid')) == leaf_uuid:
                        leaf_index = i
                        break

                if leaf_index is not None:
                    # SPLIT: Import as two separate heaps
                    self.stdout.write(self.style.SUCCESS(
                        f'Found compact boundary at message {leaf_index} - splitting into two heaps'
                    ))

                    # Heap A: messages 0 to leaf_index (inclusive)
                    messages_before_compact = lines[:leaf_index + 1]
                    heap_a, count_a, retries_a = self.import_messages_into_heap(
                        messages_before_compact,
                        era,
                        ContextHeapType.FRESH,
                        justin,
                        magent,
                        filename,
                        starting_message_number=0
                    )

                    # Create CompactingAction (will link to continuation heap after it's created)
                    # Get the preceding message (last message in heap_a, which is the leaf)
                    preceding_msg = Message.objects.get(id=leaf_uuid)

                    compact, created = CompactingAction.from_jsonl_claude_code_v2(
                        summary_data,
                        context_heap=None,  # Will be set to heap_b after it's created
                        ending_message_id=leaf_uuid,
                        preceding_message=preceding_msg
                    )

                    if created:
                        self.stdout.write(self.style.SUCCESS(
                            f'Created CompactingAction {str(compact.id)[:8]} (will link to continuation heap)'
                        ))
                    else:
                        self.stdout.write(self.style.WARNING(
                            f'CompactingAction {str(compact.id)[:8]} already exists - skipping'
                        ))

                    # Heap B: messages after leaf_index
                    if leaf_index + 1 < len(lines):
                        messages_after_compact = lines[leaf_index + 1:]
                        heap_b, count_b, retries_b = self.import_messages_into_heap(
                            messages_after_compact,
                            era,
                            ContextHeapType.POST_COMPACTING,
                            justin,
                            magent,
                            filename,
                            starting_message_number=0  # Renumber from 0
                        )

                        # Link CompactingAction to the continuation heap (Heap B)
                        compact.context_heap = heap_b
                        compact.save()
                        self.stdout.write(self.style.SUCCESS(
                            f'Linked CompactingAction to continuation heap {str(heap_b.id)[:8]}'
                        ))

                        # Link first continuation message in heap B to the CompactingAction
                        continuation = Message.objects.filter(
                            context_heap=heap_b,
                            is_continuation_message=True
                        ).order_by('message_number').first()

                        if continuation:
                            compact.continuation_message = continuation
                            compact.save()
                            self.stdout.write(self.style.SUCCESS(
                                f'Linked continuation message {str(continuation.id)[:8]} to CompactingAction'
                            ))

                        self.stdout.write(self.style.SUCCESS(
                            f'Imported {len(lines)} messages total: '
                            f'{count_a} in heap A (pre-compact), {count_b} in heap B (post-compact)'
                        ))
                    else:
                        self.stdout.write(self.style.SUCCESS(
                            f'Imported {count_a} messages (compact at end, no post-compact heap)'
                        ))

                    return
                else:
                    # Leaf not found in messages - create orphaned CA
                    self.stdout.write(self.style.WARNING(
                        f'Leaf UUID {str(leaf_uuid)[:8]} not found in messages - creating orphaned CompactingAction'
                    ))
                    # Try to find the preceding message by leafUuid (might exist from earlier import)
                    preceding_msg = None
                    try:
                        preceding_msg = Message.objects.get(id=leaf_uuid)
                    except Message.DoesNotExist:
                        pass

                    compact, _ = CompactingAction.from_jsonl_claude_code_v2(
                        summary_data,
                        context_heap=None,
                        ending_message_id=None,
                        preceding_message=preceding_msg
                    )
                    # Fall through to import all messages as single heap
            else:
                self.stdout.write(self.style.WARNING('Summary has no leafUuid'))

        # NO SPLIT: Import all messages as single FRESH heap
        heap, count, retries = self.import_messages_into_heap(
            lines,
            era,
            ContextHeapType.FRESH,
            justin,
            magent,
            filename,
            starting_message_number=0
        )

        self.stdout.write(self.style.SUCCESS(
            f'Imported {count} messages into {era.name}, window {str(heap.id)[:8]}'
        ))
        if retries > 0:
            self.stdout.write(self.style.WARNING(f'Marked {retries} messages as retries'))
